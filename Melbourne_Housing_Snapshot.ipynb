{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM84tkQzzptICivZn36erB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackcrowX/Data_Analytics_Portfolio/blob/main/Melbourne_Housing_Snapshot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  First Machine Learning Model"
      ],
      "metadata": {
        "id": "hpwO6u1lNwoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import Libraries\n",
        "\n",
        "In this initial step, we import and configure the necessary libraries for our data analysis in Jupyter Notebook. Libraries such as Pandas, NumPy, Matplotlib, and Seaborn are essential for data manipulation, numerical computations, and data visualisation."
      ],
      "metadata": {
        "id": "Vejyni1lLcQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIyKzK5ULROR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import Dataset\n",
        "\n",
        "Load the dataset into Python using Pandas as df for further analysis and exploration."
      ],
      "metadata": {
        "id": "HXnO3LgkLa6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/blackcrowX/Data_Analytics_Portfolio/main/Project_III/melborne_housing_snapshot.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "-n4ZC2I8LSbV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}